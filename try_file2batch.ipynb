{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86061/3333269111.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2024-05-16 12:59:51.239996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 12:59:51.240055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 12:59:51.241119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-16 12:59:52.071607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/data/wulingxuan/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from functools import partial\n",
    "import imp\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4, 5, 6, 7'\n",
    "import json\n",
    "import h5py\n",
    "from absl import app, flags, logging\n",
    "import flax\n",
    "from flax.traverse_util import flatten_dict\n",
    "import jax\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
    "from ml_collections import config_flags, ConfigDict\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import wandb\n",
    "from octo.data.utils.format import standardize_pytree\n",
    "import pdb\n",
    "from octo.model.components.tokenizers import LowdimObsTokenizer\n",
    "from octo.data.dataset import make_single_dataset\n",
    "from octo.model.octo_model import OctoModel\n",
    "from octo.utils.jax_utils import initialize_compilation_cache\n",
    "from octo.utils.spec import ModuleSpec\n",
    "from octo.utils.train_callbacks import (\n",
    "    RolloutVisualizationCallback,\n",
    "    SaveCallback,\n",
    "    ValidationCallback,\n",
    "    VisualizationCallback,\n",
    ")\n",
    "from octo.utils.train_utils import (\n",
    "    check_config_diff,\n",
    "    create_optimizer,\n",
    "    format_name_with_config,\n",
    "    merge_params,\n",
    "    process_text,\n",
    "    Timer,\n",
    "    TrainState,\n",
    ")\n",
    "from octo.model.components.action_heads import *\n",
    "import random\n",
    "import io\n",
    "from PIL import Image\n",
    "from octo.data.utils.format import pytree_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wulingxuan/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/data/wulingxuan/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_iter = [['/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_0.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_1.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_2.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_3.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_4.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_5.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_6.hdf5',\n",
    "              '/mnt/data_x2/wulingxuan/robot/data/arrange_fruits_by_size/episode_7.hdf5']]\n",
    "\n",
    "text_processor = OctoModel.load_pretrained('/mnt/data_x2/wulingxuan/robot/octo-small/').text_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filebatch_to_databatch(file_batch, batch_size, text_tokenizer):  \n",
    "    \n",
    "    def pad_and_resize(image, target_size):\n",
    "        original_size = image.size\n",
    "        ratio = float(target_size) / max(original_size)\n",
    "        new_size = tuple([int(x * ratio) for x in original_size])\n",
    "        \n",
    "        resized_image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        new_image = Image.new(\"RGB\", (target_size, target_size))\n",
    "        new_image.paste(resized_image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def bytes_image_to_jnp(image_bytes, image_size=128):\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        image = pad_and_resize(image, image_size)\n",
    "        image_array = jnp.array(image)\n",
    "        image_array = image_array[:,:,[2,1,0]]\n",
    "        return image_array\n",
    "  \n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    primary = []\n",
    "    wrist_left = []\n",
    "    wrist_right = []\n",
    "    action = []\n",
    "    proprio = []\n",
    "    timestep = []\n",
    "    item_per_file = batch_size / len(file_batch)\n",
    "    \n",
    "    for filename in file_batch:\n",
    "        \n",
    "        file = h5py.File(filename, 'r')\n",
    "        traj_len = file['action'].shape[0]\n",
    "        text_token = text_tokenizer.encode([str(file['instruction'])])\n",
    "        input_ids.extend([text_token['input_ids'] for _ in range(int(item_per_file))])\n",
    "        attention_mask.extend([text_token['attention_mask'] for _ in range(int(item_per_file))])\n",
    "        start_points = [random.randint(0, traj_len - 34) for _ in range(int(item_per_file))]\n",
    "        timestep.append(start_points)\n",
    "        \n",
    "        for start_point in start_points:\n",
    "            action.append(file['action'][start_point:start_point+34])\n",
    "            proprio.append(file['observations']['qpos'][start_point:start_point+2])\n",
    "            primary.append(file['observations']['images']['cam_high'][start_point:start_point+34])\n",
    "            wrist_left.append(file['observations']['images']['cam_left_wrist'][start_point:start_point+34])\n",
    "            wrist_right.append(file['observations']['images']['cam_right_wrist'][start_point:start_point+34])\n",
    "            \n",
    "    action = jnp.stack(action, axis=0)\n",
    "    proprio = jnp.stack(proprio, axis=0)\n",
    "    input_ids = jnp.stack(input_ids, axis=1).squeeze(0)\n",
    "    attention_mask = jnp.stack(attention_mask, axis=1).squeeze(0)\n",
    "    \n",
    "    batch = {}\n",
    "    batch['action'] = action\n",
    "    batch['task'] = {}\n",
    "    batch['task']['language_instruction'] = {}\n",
    "    batch['task']['language_instruction']['input_ids'] = input_ids\n",
    "    batch['task']['language_instruction']['attention_mask'] = attention_mask\n",
    "    batch['observation'] = {}\n",
    "    batch['observation']['proprio'] = proprio\n",
    "    \n",
    "    true_pad_mask = jnp.array([[True for _ in range(2)] for _ in range(batch_size)]).reshape((batch_size, 2))\n",
    "    batch['task']['pad_mask_dict'] = {'language_instruction': jnp.array([True for _ in range(batch_size)])}\n",
    "    timestep = jnp.array(timestep).reshape((batch_size, 1))\n",
    "    increment = jnp.arange(2).reshape((1, 2))\n",
    "    timestep = timestep + increment\n",
    "    batch['observation']['timestep'] = timestep\n",
    "    \n",
    "    batch['observation']['pad_mask_dict'] = {\n",
    "        'image_primary': true_pad_mask,\n",
    "        'image_wrist_left': true_pad_mask,\n",
    "        'image_wrist_right': true_pad_mask,\n",
    "    }\n",
    "    \n",
    "    batch['observation']['pad_mask'] = true_pad_mask\n",
    "    \n",
    "    for i in range(len(primary)):\n",
    "        primary[i] = jnp.stack([bytes_image_to_jnp(primary[i][j], image_size=256) for j in range(2)], axis=0)\n",
    "        wrist_left[i] = jnp.stack([bytes_image_to_jnp(wrist_left[i][j], image_size=128) for j in range(2)], axis=0)\n",
    "        wrist_right[i] = jnp.stack([bytes_image_to_jnp(wrist_right[i][j], image_size=128) for j in range(2)], axis=0)\n",
    "        \n",
    "    primary = jnp.stack(primary, axis=0)\n",
    "    wrist_left = jnp.stack(wrist_left, axis=0)\n",
    "    wrist_right = jnp.stack(wrist_right, axis=0)\n",
    "    batch['observation']['image_primary'] = primary\n",
    "    batch['observation']['image_wrist_left'] = wrist_left\n",
    "    batch['observation']['image_wrist_right'] = wrist_right\n",
    "    batch['absolute_action_mask'] = jnp.ones((batch_size, 14))\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = map(\n",
    "    partial(filebatch_to_databatch, batch_size=32, text_tokenizer = text_processor), file_iter\n",
    ")\n",
    "example_batch = next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['action', 'task', 'observation', 'absolute_action_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 34, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['task']['language_instruction']['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"absolute_action_mask\": \"Shape: (32, 14)\",\n",
      "    \"action\": \"Shape: (32, 34, 14)\",\n",
      "    \"observation\": {\n",
      "        \"image_primary\": \"Shape: (32, 2, 256, 256, 3)\",\n",
      "        \"image_wrist_left\": \"Shape: (32, 2, 128, 128, 3)\",\n",
      "        \"image_wrist_right\": \"Shape: (32, 2, 128, 128, 3)\",\n",
      "        \"pad_mask\": \"Shape: (32, 2)\",\n",
      "        \"pad_mask_dict\": {\n",
      "            \"image_primary\": \"Shape: (32, 2)\",\n",
      "            \"image_wrist_left\": \"Shape: (32, 2)\",\n",
      "            \"image_wrist_right\": \"Shape: (32, 2)\"\n",
      "        },\n",
      "        \"proprio\": \"Shape: (32, 2, 14)\",\n",
      "        \"timestep\": \"Shape: (32, 2)\"\n",
      "    },\n",
      "    \"task\": {\n",
      "        \"language_instruction\": {\n",
      "            \"attention_mask\": \"Shape: (32, 16)\",\n",
      "            \"input_ids\": \"Shape: (32, 16)\"\n",
      "        },\n",
      "        \"pad_mask_dict\": {\n",
      "            \"language_instruction\": \"Shape: (32,)\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pytree_display(example_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
