{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 19:28:05.468640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 19:28:05.468681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 19:28:05.470843: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 19:28:06.614726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from absl import app, flags, logging\n",
    "import flax\n",
    "import jax\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from octo.data.dataset import make_single_dataset\n",
    "from octo.data.utils.data_utils import NormalizationType\n",
    "from octo.model.components.action_heads import L1ActionHead\n",
    "from octo.model.components.tokenizers import LowdimObsTokenizer\n",
    "from octo.model.octo_model import OctoModel\n",
    "from octo.utils.jax_utils import initialize_compilation_cache\n",
    "from octo.utils.spec import ModuleSpec\n",
    "from octo.utils.train_utils import (\n",
    "    freeze_weights,\n",
    "    merge_params,\n",
    "    process_text,\n",
    "    TrainState,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj {'action': <tf.Tensor 'args_3:0' shape=(None, 14) dtype=float32>, 'observation': {'state': <tf.Tensor 'args_9:0' shape=(None, 14) dtype=float32>, 'top': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>}, 'discount': <tf.Tensor 'args_4:0' shape=(None,) dtype=float32>, 'is_first': <tf.Tensor 'args_5:0' shape=(None,) dtype=bool>, 'language_instruction': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'is_terminal': <tf.Tensor 'args_7:0' shape=(None,) dtype=bool>, 'reward': <tf.Tensor 'args_11:0' shape=(None,) dtype=float32>, 'is_last': <tf.Tensor 'args_6:0' shape=(None,) dtype=bool>, 'traj_metadata': {'episode_metadata': {'file_path': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>}}, '_len': <tf.Tensor 'args_1:0' shape=(None,) dtype=int32>, '_traj_index': <tf.Tensor 'args_2:0' shape=(None,) dtype=int64>, '_frame_index': <tf.Tensor 'args_0:0' shape=(None,) dtype=int32>}\n",
      "image_obs_keys {'primary': 'top'}\n",
      "state_obs_keys ['state']\n",
      "{\n",
      "    \"action\": {\n",
      "        \"max\": \"Shape: (14,)\",\n",
      "        \"mean\": \"Shape: (14,)\",\n",
      "        \"min\": \"Shape: (14,)\",\n",
      "        \"std\": \"Shape: (14,)\"\n",
      "    },\n",
      "    \"num_trajectories\": \"Shape: ()\",\n",
      "    \"num_transitions\": \"Shape: ()\",\n",
      "    \"proprio\": {\n",
      "        \"max\": \"Shape: (14,)\",\n",
      "        \"mean\": \"Shape: (14,)\",\n",
      "        \"min\": \"Shape: (14,)\",\n",
      "        \"std\": \"Shape: (14,)\"\n",
      "    }\n",
      "}\n",
      "{'train': <SplitInfo num_examples=50, num_shards=8>}\n",
      "True\n",
      "<DLataset element_spec={'action': TensorSpec(shape=(None, 14), dtype=tf.float32, name=None), 'observation': {'state': TensorSpec(shape=(None, 14), dtype=tf.float32, name=None), 'top': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, 'discount': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'is_first': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'language_instruction': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'is_terminal': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'reward': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'is_last': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'traj_metadata': {'episode_metadata': {'file_path': TensorSpec(shape=(None,), dtype=tf.string, name=None)}}, '_len': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '_traj_index': TensorSpec(shape=(None,), dtype=tf.int64, name=None), '_frame_index': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}>\n",
      "{\n",
      "    \"_frame_index\": \"Shape: (400,)\",\n",
      "    \"_len\": \"Shape: (400,)\",\n",
      "    \"_traj_index\": \"Shape: (400,)\",\n",
      "    \"action\": \"Shape: (400, 14)\",\n",
      "    \"discount\": \"Shape: (400,)\",\n",
      "    \"is_first\": \"Shape: (400,)\",\n",
      "    \"is_last\": \"Shape: (400,)\",\n",
      "    \"is_terminal\": \"Shape: (400,)\",\n",
      "    \"language_instruction\": \"Shape: (400,)\",\n",
      "    \"observation\": {\n",
      "        \"state\": \"Shape: (400, 14)\",\n",
      "        \"top\": \"Shape: (400,)\"\n",
      "    },\n",
      "    \"reward\": \"Shape: (400,)\",\n",
      "    \"traj_metadata\": {\n",
      "        \"episode_metadata\": {\n",
      "            \"file_path\": \"Shape: (400,)\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "traj {'action': <tf.Tensor 'args_3:0' shape=(None, 14) dtype=float32>, 'observation': {'state': <tf.Tensor 'args_9:0' shape=(None, 14) dtype=float32>, 'top': <tf.Tensor 'args_10:0' shape=(None,) dtype=string>}, 'discount': <tf.Tensor 'args_4:0' shape=(None,) dtype=float32>, 'is_first': <tf.Tensor 'args_5:0' shape=(None,) dtype=bool>, 'language_instruction': <tf.Tensor 'args_8:0' shape=(None,) dtype=string>, 'is_terminal': <tf.Tensor 'args_7:0' shape=(None,) dtype=bool>, 'reward': <tf.Tensor 'args_11:0' shape=(None,) dtype=float32>, 'is_last': <tf.Tensor 'args_6:0' shape=(None,) dtype=bool>, 'traj_metadata': {'episode_metadata': {'file_path': <tf.Tensor 'args_12:0' shape=(None,) dtype=string>}}, '_len': <tf.Tensor 'args_1:0' shape=(None,) dtype=int32>, '_traj_index': <tf.Tensor 'args_2:0' shape=(None,) dtype=int64>, '_frame_index': <tf.Tensor 'args_0:0' shape=(None,) dtype=int32>}\n",
      "image_obs_keys {'primary': 'top'}\n",
      "state_obs_keys ['state']\n",
      "{\n",
      "    \"absolute_action_mask\": \"Shape: (400, 14)\",\n",
      "    \"action\": \"Shape: (400, 14)\",\n",
      "    \"dataset_name\": \"Shape: (400,)\",\n",
      "    \"observation\": {\n",
      "        \"image_primary\": \"Shape: (400,)\",\n",
      "        \"proprio\": \"Shape: (400, 14)\",\n",
      "        \"timestep\": \"Shape: (400,)\"\n",
      "    },\n",
      "    \"task\": {\n",
      "        \"language_instruction\": \"Shape: (400,)\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"absolute_action_mask\": \"Shape: (400, 14)\",\n",
      "    \"action\": \"Shape: (400, 14)\",\n",
      "    \"dataset_name\": \"Shape: (400,)\",\n",
      "    \"observation\": {\n",
      "        \"image_primary\": \"Shape: (400,)\",\n",
      "        \"proprio\": \"Shape: (400, 14)\",\n",
      "        \"timestep\": \"Shape: (400,)\"\n",
      "    },\n",
      "    \"task\": {\n",
      "        \"language_instruction\": \"Shape: (400,)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset = make_single_dataset(\n",
    "    dataset_kwargs=dict(\n",
    "        name=\"aloha_sim_cube_scripted_dataset\",\n",
    "        data_dir='/root/autodl-tmp/aloha_sim_dataset',\n",
    "        image_obs_keys={\"primary\": \"top\"},\n",
    "        state_obs_keys=[\"state\"],\n",
    "        language_key=\"language_instruction\",\n",
    "        action_proprio_normalization_type=NormalizationType.NORMAL,\n",
    "        absolute_action_mask=[True] * 14,\n",
    "    ),\n",
    "    traj_transform_kwargs=dict(\n",
    "        window_size=1,\n",
    "        future_action_window_size=49,  # so we get 50 actions for our action chunk\n",
    "    ),\n",
    "    frame_transform_kwargs=dict(\n",
    "        resize_size={\"primary\": (256, 256)},\n",
    "    ),\n",
    "    train=True,\n",
    ")\n",
    "original_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = (\n",
    "    dataset.repeat()\n",
    "    .unbatch()\n",
    "    .shuffle(10000)  # can reduce this if RAM consumption too high\n",
    "    .batch(128)\n",
    "    .iterator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/data1/zhuxiaopei/octo-small/config.json; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mOctoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data1/zhuxiaopei/octo-small\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m text_processor \u001b[38;5;241m=\u001b[39m pretrained_model\u001b[38;5;241m.\u001b[39mtext_processor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_batch\u001b[39m(batch):\n",
      "File \u001b[0;32m~/octo-baseline/octo/model/octo_model.py:228\u001b[0m, in \u001b[0;36mOctoModel.load_pretrained\u001b[0;34m(cls, checkpoint_path, step)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# load config\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(\n\u001b[1;32m    226\u001b[0m     tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 228\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# load example batch\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(\n\u001b[1;32m    232\u001b[0m     tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_batch.msgpack\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/lib/io/file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    118\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/lib/io/file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /data1/zhuxiaopei/octo-small/config.json; No such file or directory"
     ]
    }
   ],
   "source": [
    "pretrained_model = OctoModel.load_pretrained('/data1/zhuxiaopei/octo-small')\n",
    "text_processor = pretrained_model.text_processor\n",
    "def process_batch(batch):\n",
    "    batch = process_text(batch, text_processor)\n",
    "    del batch[\"dataset_name\"]\n",
    "    return batch\n",
    "train_data_iter = map(process_batch, train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(pretrained_model.config, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def print_shape_or_value(x):\n",
    "    if isinstance(x, (jnp.ndarray, np.ndarray, tf.Tensor)):\n",
    "        return f\"Shape: {x.shape}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def apply_to_nested_dict(func, d):\n",
    "    if isinstance(d, dict):\n",
    "        return {k: apply_to_nested_dict(func, v) for k, v in d.items()}\n",
    "    else:\n",
    "        return func(d)\n",
    "\n",
    "converted_tree = jax.tree_util.tree_map(print_shape_or_value, example_batch)\n",
    "formatted_output = json.dumps(converted_tree, indent=4)\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_batch['task']['language_instruction']['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_batch['task']['language_instruction']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_batch['task']['pad_mask_dict']['language_instruction'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(example_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_one = original_dataset.take(1)\n",
    "for step in take_one:\n",
    "    print(json.dumps(jax.tree_map(print_shape_or_value, step), indent=4))\n",
    "    print(step['task']['language_instruction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
